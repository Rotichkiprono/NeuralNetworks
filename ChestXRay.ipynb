{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9681947,
          "sourceType": "datasetVersion",
          "datasetId": 5918106
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "üì°ACC:98%„ÄåConvNeXtTiny„ÄçüåêChest X-Ray",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; border:#B7B7A4 solid; padding:15px; background-color:#F0EFEB; font-size:110%; text-align:left\">\n",
        "    \n",
        "  <p style=\"display: inline-block; padding: 7px; background-color: #000000; color: #F0EFEB; text-decoration: none; border-radius: 5px 5px; font-size: 200%; text-align: left; border: 1.5px solid #283618; font-family: 'New Times Roman', serif;\">Title : Chest X-Ray Dataset</p>    \n",
        "  \n",
        "  <p style=\"font-size: 120%; text-align: center; color: #6B705C; margin-top: 10px;\">If you feel my notebook helpful, support with one upvote, thank you</p>\n",
        "  \n",
        "  <p style=\"font-size: 120%; text-align: center; color: #6B705C; margin-top: 10px; font-weight: bold;\">Created by Mr.Tao  29/10/2024üëç</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "iqjjgTLorX-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color: #F0EFEB; text-align:left; font-size:120%\">\n",
        "\n",
        "<h4 align=\"left\"><span style=\"font-weight:900; font-size:200%\"><font color=blue>üìÅ About Dataset</font></span></h4>    \n",
        "    \n",
        "The chest X-ray image dataset consists of images categorized into four distinct classes: pneumonia, tuberculosis, corona (COVID-19), and normal. Each class represents chest X-ray images of patients diagnosed with the respective condition or healthy individuals for the normal class. The dataset is intended to support research in medical image analysis, particularly for the automated detection and classification of respiratory diseases using machine learning and deep learning techniques.\n",
        "Classes: Pneumonia, Tuberculosis, Corona, Normal\n",
        "Image Format: Typically in .jpg or .png format\n",
        "Resolution: Variable, often resized to uniform dimensions (e.g., 224x224) for model training\n",
        "Usage: Suitable for training and testing classification models to differentiate between the four respiratory conditions"
      ],
      "metadata": {
        "id": "ypB8TYZGrX-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius: 10px; border: 1px solid #B7B7A4; padding: 20px; background-color: #F9F9F9; font-size: 110%; text-align: left; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"display: inline-block; padding: 10px 20px; background-color: #B7B7A4; color: #F0EFEB; text-decoration: none; border-radius: 5px; font-size: 160%; text-align: left; border: 1.5px solid #B7B7A4; font-family: 'Times New Roman', serif; margin-bottom: 20px;\">\n",
        "        Table of Contents\n",
        "    </h1>\n",
        "    <p style=\"margin: 0;\">\n",
        "        <a id=\"toc\"></a>\n",
        "        <ul style=\"list-style: none; padding: 0;\">\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#1\" style=\"color: #2E8B57; text-decoration: none;\">1. Import Libraries</a></li>\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#2\" style=\"color: #2E8B57; text-decoration: none;\">2. Read Dataset</a></li>\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#3\" style=\"color: #2E8B57; text-decoration: none;\">3. Visualization</a></li>\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#4\" style=\"color: #2E8B57; text-decoration: none;\">4. Preprocessing</a></li>\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#5\" style=\"color: #2E8B57; text-decoration: none;\">5. Modeling</a></li>\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#6\" style=\"color: #2E8B57; text-decoration: none;\">6. Training</a></li>\n",
        "            <li style=\"margin-bottom: 10px;\"><a href=\"#7\" style=\"color: #2E8B57; text-decoration: none;\">7. Model Performance</a></li>\n",
        "        </ul>\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "aMqkRh5UrX-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"1\"></a>\n",
        "# **<h1 id=\"1\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Import Libraries</h1>**"
      ],
      "metadata": {
        "id": "C6NcPqd-rX-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.metrics import confusion_matrix , accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import glob\n",
        "import pandas as pan\n",
        "import matplotlib.pyplot as plotter\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:12.063554Z",
          "iopub.execute_input": "2024-10-29T11:29:12.064369Z",
          "iopub.status.idle": "2024-10-29T11:29:12.071533Z",
          "shell.execute_reply.started": "2024-10-29T11:29:12.064328Z",
          "shell.execute_reply": "2024-10-29T11:29:12.070526Z"
        },
        "trusted": true,
        "id": "HRSaLP-yrX-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"2\"></a>\n",
        "# **<h1 id=\"2\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Read Dataset</h1>**"
      ],
      "metadata": {
        "id": "dkP659F3rX-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train Files_Name\n",
        "image_data='/kaggle/input/chest-x-ray-dataset-4-categories/Chest X_Ray Dataset'\n",
        "train_files = [i for i in glob.glob(image_data + \"//*//*\")]\n",
        "np.random.shuffle(train_files)\n",
        "train_labels = [os.path.dirname(i).split(\"/\")[-1] for i in train_files]\n",
        "train_data = zip(train_files, train_labels)\n",
        "train_df = pd.DataFrame(train_data, columns=[\"Image\", \"Label\"])\n",
        "train_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:12.073093Z",
          "iopub.execute_input": "2024-10-29T11:29:12.073421Z",
          "iopub.status.idle": "2024-10-29T11:29:12.14212Z",
          "shell.execute_reply.started": "2024-10-29T11:29:12.073388Z",
          "shell.execute_reply": "2024-10-29T11:29:12.141127Z"
        },
        "trusted": true,
        "id": "7PY8aUJZrX-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3\"></a>\n",
        "# **<h1 id=\"3\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Visualization</h1>**"
      ],
      "metadata": {
        "id": "v43P4IUtrX-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a theme for better aesthetics\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Calculate counts and percentages for each label\n",
        "count_data = train_df[\"Label\"].value_counts()\n",
        "percentage_data = train_df[\"Label\"].value_counts(normalize=True) * 100  # Calculate percentage\n",
        "\n",
        "# Print percentage for each label (optional)\n",
        "print(percentage_data)\n",
        "\n",
        "# Sort the labels based on count values in descending order\n",
        "sorted_data = count_data.sort_values(ascending=False).index\n",
        "\n",
        "# Create a color palette for the bars\n",
        "palette = sns.color_palette(\"pastel\", len(sorted_data))\n",
        "\n",
        "# Plot the count plot with sorted labels\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.countplot(x=train_df[\"Label\"], order=sorted_data, palette=palette)\n",
        "\n",
        "# Annotate each bar with the percentage value\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()  # Get the height of the bar\n",
        "    percentage = f'{(height / count_data.sum()) * 100:.2f}%'  # Calculate percentage\n",
        "    ax.annotate(percentage,  # The label to be annotated\n",
        "                (p.get_x() + p.get_width() / 2., height),  # Position of the label\n",
        "                ha='center', va='bottom', fontsize=10, color='black', xytext=(0, 8), textcoords='offset points')\n",
        "\n",
        "# Rotate x-axis labels for better visibility and set the label font size\n",
        "plt.xticks(rotation=0, ha='right', fontsize=12)\n",
        "\n",
        "# Add title and labels with improved fonts and padding\n",
        "plt.title(\"Label Distribution with Percentages\", fontsize=16, pad=20)\n",
        "plt.xlabel(\"Labels\", fontsize=14, labelpad=10)\n",
        "plt.ylabel(\"Count\", fontsize=14, labelpad=10)\n",
        "\n",
        "# Remove the top and right spines for a cleaner look\n",
        "sns.despine()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:12.143722Z",
          "iopub.execute_input": "2024-10-29T11:29:12.14405Z",
          "iopub.status.idle": "2024-10-29T11:29:12.585998Z",
          "shell.execute_reply.started": "2024-10-29T11:29:12.144017Z",
          "shell.execute_reply": "2024-10-29T11:29:12.585013Z"
        },
        "trusted": true,
        "id": "M84jobcirX-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5><span style=\"align:left; color:black; font-weight:550; font-size:110%\">\n",
        "    ‚û°Ô∏è  Visualize the number of four categories.\n",
        "</span></h5>"
      ],
      "metadata": {
        "id": "bnuwv28ZrX-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4\"></a>\n",
        "# **<h1 id=\"4\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Preprocessing</h1>**"
      ],
      "metadata": {
        "id": "2Y29yh3JrX-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">keras.preprocessing</h3>\n",
        "directory : Directory where the data is located. If labels is \"inferred\", it should contain subdirectories, each containing images for a class. Otherwise, the directory structure is ignored.\n",
        "\n",
        "batch_size : Size of the batches of data. If None, the data will not be batched (the dataset will yield individual samples). Defaults to 32.\n",
        "\n",
        "image_size : Size to resize images to after they are read from disk, specified as (height, width). Since the pipeline processes batches of images that must all have the same size, this must be provided.\n",
        "\n",
        "seed : Optional random seed for shuffling and transformations.\n",
        "\n",
        "validation_split : Optional float between 0 and 1, fraction of data to reserve for validation.\n",
        "\n",
        "subset : Subset of the data to return. One of \"training\", \"validation\", or \"both\". Only used if validation_split is set. When subset=\"both\", the utility returns a tuple of two datasets (the training and validation datasets respectively)."
      ],
      "metadata": {
        "id": "LNtIFhxurX-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">Split the data into train, validation, and test sets</h3>"
      ],
      "metadata": {
        "id": "DGGniMR4rX-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up variables\n",
        "train_data_dir = image_data\n",
        "batch_size = 8\n",
        "target_size = (224, 224)\n",
        "validation_split = 0.25  # Total split for validation + test\n",
        "seed = 100\n",
        "\n",
        "# Generate training + validation dataset\n",
        "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    validation_split=validation_split,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    image_size=target_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "# Generate validation + test dataset\n",
        "val_test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    validation_split=validation_split,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=target_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "# Calculate test dataset size (assuming a split of 80% train, 10% validation, and 10% test)\n",
        "val_size = math.floor(len(val_test_dataset) * 0.5)\n",
        "test_size = len(val_test_dataset) - val_size\n",
        "\n",
        "# Further split into validation and test datasets\n",
        "validation = val_test_dataset.take(val_size)\n",
        "test = val_test_dataset.skip(val_size)\n",
        "\n",
        "# Check the sample count for each dataset\n",
        "print(f\"Training samples: {len(train)}, Validation samples: {val_size}, Test samples: {test_size}\")\n",
        "\n",
        "# Sample counts for each dataset\n",
        "train_samples = len(train)\n",
        "val_samples = val_size\n",
        "test_samples = test_size\n",
        "\n",
        "# Names for the datasets\n",
        "datasets = ['Training', 'Validation', 'Test']\n",
        "sample_counts = [train_samples, val_samples, test_samples]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(datasets, sample_counts, color=['blue', 'orange', 'green'])\n",
        "plt.xlabel('Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Samples', fontsize=14)\n",
        "plt.title('Sample Distribution in Datasets', fontsize=16)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.ylim(0, max(sample_counts) + 100)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:12.587421Z",
          "iopub.execute_input": "2024-10-29T11:29:12.587827Z",
          "iopub.status.idle": "2024-10-29T11:29:18.851136Z",
          "shell.execute_reply.started": "2024-10-29T11:29:12.587783Z",
          "shell.execute_reply": "2024-10-29T11:29:18.84983Z"
        },
        "trusted": true,
        "id": "yteZLdmHrX-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5><span style=\"align:left; color:black; font-weight:550; font-size:110%\">\n",
        "    ‚û°Ô∏è  Split 75% for training, 12.5% for validation, and 12.5% for test.\n",
        "</span></h5>"
      ],
      "metadata": {
        "id": "ZTWxaWUhrX-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train.class_names\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "num_images_per_class = 2\n",
        "count = {class_name: 0 for class_name in class_names}\n",
        "\n",
        "for images, labels in train.take(1):\n",
        "    for i in range(len(labels)):\n",
        "        label = class_names[labels[i]]\n",
        "        if count[label] < num_images_per_class:\n",
        "            ax = plt.subplot(8, 4, sum(count.values()) + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(label)\n",
        "            plt.axis(\"off\")\n",
        "            count[label] += 1\n",
        "        if sum(count.values()) >= num_images_per_class * len(class_names):\n",
        "            break  #"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:18.853788Z",
          "iopub.execute_input": "2024-10-29T11:29:18.854196Z",
          "iopub.status.idle": "2024-10-29T11:29:19.868781Z",
          "shell.execute_reply.started": "2024-10-29T11:29:18.854144Z",
          "shell.execute_reply": "2024-10-29T11:29:19.867708Z"
        },
        "trusted": true,
        "id": "43FwcSLHrX-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5><span style=\"align:left; color:black; font-weight:550; font-size:110%\">\n",
        "    ‚û°Ô∏è  Observe the photos corresponding to each class.\n",
        "</span></h5>"
      ],
      "metadata": {
        "id": "TupwyCGHrX-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5\"></a>\n",
        "# **<h1 id=\"5\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Modeling</h1>**"
      ],
      "metadata": {
        "id": "XgxycbW8rX-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">Keras Application</h3>\n",
        "\n",
        "ConvNeXt is a family of convolutional neural network architectures that aim to improve upon traditional CNNs by adopting some principles from Transformer-based models. ConvNeXt Tiny is the smallest variant in this family, designed to strike a balance between model efficiency and performance."
      ],
      "metadata": {
        "id": "Rgq0yRHArX-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">About setting</h3>\n",
        "input_shape : Optional shape tuple, to be specified if you would like to use a model with an input image resolution that is not (224, 224, 3). It should have exactly 3 inputs channels (224, 224, 3). You can also omit this option if you would like to infer input_shape from an input_tensor. If you choose to include both input_tensor and input_shape then input_shape will be used if they match, if the shapes do not match then we will throw an error. E.g. (160, 160, 3) would be one valid value.\n",
        "\n",
        "include_top : Boolean, whether to include the fully-connected layer at the top of the network. Defaults to True.\n",
        "\n",
        "weights : String, one of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded."
      ],
      "metadata": {
        "id": "4nv2zWujrX-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"font-size:24px;\">The training accuracy lags behind the validation accuracy, it might indicate underfitting, or that the model isn't learning the training data well enough. Here are some strategies to improve the training accuracy</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">1.Load the Base Model</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">2.Freeze the Base Model</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">3.Create the Keras Model , and add the Base Model</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">4.Add Global Average Pooling Layer</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">5.Add Dense Layer with L2 Regularization</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">6.Add Batch Normalization , and Activation Layer</span>\n",
        "\n",
        "### <span style=\"font-size:20px;\">7.Add Dropout Layer(0.5)</span>"
      ],
      "metadata": {
        "id": "YHCllbErrX-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the base model\n",
        "base_model = tf.keras.applications.ConvNeXtTiny(input_shape=(224, 224, 3),include_top=False,weights='imagenet')\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Create the Keras model\n",
        "keras_model = keras.models.Sequential()\n",
        "keras_model.add(base_model)\n",
        "keras_model.add(keras.layers.GlobalAveragePooling2D())\n",
        "keras_model.add(keras.layers.Dense(256, activation=None, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "keras_model.add(keras.layers.BatchNormalization())\n",
        "keras_model.add(keras.layers.Activation('relu'))\n",
        "keras_model.add(keras.layers.Dropout(0.5))\n",
        "keras_model.add(keras.layers.Dense(4,activation=tf.nn.softmax))\n",
        "keras_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:19.870538Z",
          "iopub.execute_input": "2024-10-29T11:29:19.871173Z",
          "iopub.status.idle": "2024-10-29T11:29:21.040545Z",
          "shell.execute_reply.started": "2024-10-29T11:29:19.871128Z",
          "shell.execute_reply": "2024-10-29T11:29:21.03963Z"
        },
        "trusted": true,
        "id": "Aj_ocGB2rX-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with an optimizer and learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "keras_model.compile(optimizer=optimizer,\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:21.042018Z",
          "iopub.execute_input": "2024-10-29T11:29:21.042784Z",
          "iopub.status.idle": "2024-10-29T11:29:21.052141Z",
          "shell.execute_reply.started": "2024-10-29T11:29:21.042726Z",
          "shell.execute_reply": "2024-10-29T11:29:21.051193Z"
        },
        "trusted": true,
        "id": "LXO-VIrJrX-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model.build(input_shape=(None, 224, 224, 3))\n",
        "dummy_input = tf.random.normal((1, 224, 224, 3))\n",
        "keras_model(dummy_input)\n",
        "tf.keras.utils.plot_model(keras_model, to_file='model.png', show_shapes=True, show_layer_names=True, show_dtype=True, dpi=80)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:21.053346Z",
          "iopub.execute_input": "2024-10-29T11:29:21.055515Z",
          "iopub.status.idle": "2024-10-29T11:29:22.235942Z",
          "shell.execute_reply.started": "2024-10-29T11:29:21.055472Z",
          "shell.execute_reply": "2024-10-29T11:29:22.234473Z"
        },
        "trusted": true,
        "id": "ZTgb5FcSrX-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">ModelCheckpoint</h3>\n",
        "Callback to save the Keras model or model weights at some frequency.\n",
        "\n",
        "ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.\n",
        "\n",
        "<h3 style=\"font-weight:700\">EarlyStopping</h3>\n",
        "Stop training when a monitored metric has stopped improving.."
      ],
      "metadata": {
        "id": "Jy8Q5UX2rX-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks for early stopping and saving the best model\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(filepath='best_model.keras', save_best_only=True)\n",
        "]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:22.237768Z",
          "iopub.execute_input": "2024-10-29T11:29:22.238111Z",
          "iopub.status.idle": "2024-10-29T11:29:22.242871Z",
          "shell.execute_reply.started": "2024-10-29T11:29:22.238077Z",
          "shell.execute_reply": "2024-10-29T11:29:22.241958Z"
        },
        "trusted": true,
        "id": "3fLJdivwrX-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"6\"></a>\n",
        "# **<h1 id=\"6\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Training</h1>**"
      ],
      "metadata": {
        "id": "pEnIP2OwrX-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = keras_model.fit(train,validation_data=validation,\n",
        "                           epochs=10,  # Adjust as needed\n",
        "                           callbacks=callbacks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:29:22.244253Z",
          "iopub.execute_input": "2024-10-29T11:29:22.244548Z",
          "iopub.status.idle": "2024-10-29T11:41:02.306553Z",
          "shell.execute_reply.started": "2024-10-29T11:29:22.244517Z",
          "shell.execute_reply": "2024-10-29T11:41:02.302669Z"
        },
        "trusted": true,
        "id": "iF-C7xDzrX-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"7\"></a>\n",
        "# **<h1 id=\"7\" style=\"background-color:#F0EFEB;font-family:newtimeroman;font-size:150%;color:#283618;text-align:center;border-radius:15px 15px;padding:7px;border:solid 3px #B7B7A4;\">Model Performance</h1>**"
      ],
      "metadata": {
        "id": "LW73Ld-rrX-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">1.Visualize the changes in loss and accuracy during the model training process.</h3>"
      ],
      "metadata": {
        "id": "FbDQrh2lrX-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_=pd.DataFrame(history.history)\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.title('Loss Over Epochs', fontsize=16, weight='bold')\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.title('Accuracy Over Epochs', fontsize=16, weight='bold')\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:41:02.309872Z",
          "iopub.execute_input": "2024-10-29T11:41:02.310467Z",
          "iopub.status.idle": "2024-10-29T11:41:03.141109Z",
          "shell.execute_reply.started": "2024-10-29T11:41:02.310425Z",
          "shell.execute_reply": "2024-10-29T11:41:03.140117Z"
        },
        "trusted": true,
        "id": "c3DP64uYrX-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">2.Evaluate the model on the validation set and print the loss and accuracy</h3>"
      ],
      "metadata": {
        "id": "M4e0sxy4rX-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = keras_model.evaluate(test)\n",
        "print('Test Loss =', score)\n",
        "print('Test Accuracy =', acc)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:41:03.142354Z",
          "iopub.execute_input": "2024-10-29T11:41:03.142681Z",
          "iopub.status.idle": "2024-10-29T11:41:12.609923Z",
          "shell.execute_reply.started": "2024-10-29T11:41:03.142646Z",
          "shell.execute_reply": "2024-10-29T11:41:12.609015Z"
        },
        "trusted": true,
        "id": "Q9_Nf03YrX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">3.Visualize the model's prediction results through a confusion matrix.</h3>"
      ],
      "metadata": {
        "id": "VlXiFRTLrX-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store true labels and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Iterate through the validation dataset to extract true labels and predictions\n",
        "for images, labels in validation:\n",
        "\n",
        "    y_true.extend(labels.numpy())\n",
        "    preds = keras_model.predict(images, verbose=0)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "# Convert the lists to NumPy arrays for further processing\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate the confusion matrix based on the true and predicted labels\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=train.class_names,\n",
        "            yticklabels=train.class_names)\n",
        "plt.xlabel('Predicted Label', fontsize=14)\n",
        "plt.ylabel('True Label', fontsize=14)\n",
        "plt.title('Confusion Matrix', fontsize=16, weight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:41:12.611241Z",
          "iopub.execute_input": "2024-10-29T11:41:12.61157Z",
          "iopub.status.idle": "2024-10-29T11:41:25.245911Z",
          "shell.execute_reply.started": "2024-10-29T11:41:12.611534Z",
          "shell.execute_reply": "2024-10-29T11:41:25.244931Z"
        },
        "trusted": true,
        "id": "fPEFeU4OrX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">4.Visualize the model's prediction results by displaying a set of images from the validation dataset along with their true labels and predicted labels.</h3>"
      ],
      "metadata": {
        "id": "UIbgEbl3rX-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store true labels and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Initialize a list to store images for visualization\n",
        "images_for_display = []\n",
        "\n",
        "# Iterate through the validation dataset to extract true labels and predictions\n",
        "for images, labels in validation:\n",
        "    y_true.extend(labels.numpy())\n",
        "    preds = keras_model.predict(images, verbose=0)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "    # Store images and labels for display\n",
        "    images_for_display.extend(images.numpy())\n",
        "\n",
        "# Convert the lists to NumPy arrays for further processing\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Define the number of images to display\n",
        "num_images_to_display = 10\n",
        "num_images_available = min(num_images_to_display, len(images_for_display))\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot images with their true and predicted labels\n",
        "for i in range(num_images_available):\n",
        "    ax = plt.subplot(2, 5, i + 1)  # Create a 2-row, 5-column grid\n",
        "    plt.imshow(images_for_display[i].astype(\"uint8\"))\n",
        "    true_label = class_names[y_true[i]]\n",
        "    predicted_label = class_names[y_pred[i]]\n",
        "    plt.title(f'True: {true_label}\\nPred: {predicted_label}', fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:41:25.247329Z",
          "iopub.execute_input": "2024-10-29T11:41:25.24844Z",
          "iopub.status.idle": "2024-10-29T11:41:37.790944Z",
          "shell.execute_reply.started": "2024-10-29T11:41:25.248393Z",
          "shell.execute_reply": "2024-10-29T11:41:37.789939Z"
        },
        "trusted": true,
        "id": "QgKocugPrX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"font-weight:700\">5.Visualize the model's prediction results by displaying a set of images from the validation dataset along with their true labels and predicted labels for incorrect predictions.</h3>"
      ],
      "metadata": {
        "id": "1S_655_XrX-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store true labels, predicted labels, and images for display\n",
        "y_true = []\n",
        "y_pred = []\n",
        "images_for_display = []\n",
        "\n",
        "# Iterate through the validation dataset to extract true labels and predictions\n",
        "for images, labels in validation:\n",
        "    y_true.extend(labels.numpy())\n",
        "    preds = keras_model.predict(images, verbose=0)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "    # Store images and labels for display\n",
        "    images_for_display.extend(images.numpy())\n",
        "\n",
        "# Convert lists to NumPy arrays for further processing\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "images_for_display = np.array(images_for_display)\n",
        "\n",
        "# Find incorrect predictions\n",
        "incorrect_indices = np.where(y_true != y_pred)[0]\n",
        "\n",
        "# Define the number of incorrect images to display\n",
        "num_images_to_display = 10\n",
        "num_images_available = min(num_images_to_display, len(incorrect_indices))\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot incorrect predictions\n",
        "for i in range(num_images_available):\n",
        "    idx = incorrect_indices[i]\n",
        "    ax = plt.subplot(2, 5, i + 1)  # Create a 2-row, 5-column grid\n",
        "    plt.imshow(images_for_display[idx].astype(\"uint8\"))\n",
        "    true_label = class_names[y_true[idx]]\n",
        "    predicted_label = class_names[y_pred[idx]]\n",
        "    plt.title(f'True: {true_label}\\nPred: {predicted_label}', fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-29T11:41:37.792199Z",
          "iopub.execute_input": "2024-10-29T11:41:37.792524Z",
          "iopub.status.idle": "2024-10-29T11:41:50.105678Z",
          "shell.execute_reply.started": "2024-10-29T11:41:37.792485Z",
          "shell.execute_reply": "2024-10-29T11:41:50.104773Z"
        },
        "trusted": true,
        "id": "oeN9vySprX-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color: #F0EFEB; text-align:left; font-size:120%\">\n",
        "\n",
        "<h4 align=\"left\"><span style=\"font-weight:900; font-size:200%\"><font color=#d10202>üìÅ Thank you</font></span></h4>    \n",
        "    \n",
        "I am using the ConvNeXt model for the first time, which is one of the highly accurate models in Keras. Although the prediction time is longer, I believe it is more accurate than ResNet, VGG, MobileNet, EfficientNet, and Xception. I welcome everyone to support my work and give me a upvote!Thank you !"
      ],
      "metadata": {
        "id": "bkXZWRGRrX-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; padding: 15px; background-color:navy\">\n",
        "<h4 align=\"center\"><span style=\"font-weight:1000; font-size:500%; text-shadow:3px 3px 20px #add8e6\"><font color=#ffffff>Upvote and Comment</font></span></h4>"
      ],
      "metadata": {
        "id": "D0SnV_1hrX-b"
      }
    }
  ]
}